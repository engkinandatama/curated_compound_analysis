{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Compound Data Curation Pipeline\n",
        "\n",
        "**Purpose**: Extract CID and SMILES from compound names using PubChem API\n",
        "\n",
        "**Input**: CSV file with compound names\n",
        "**Output**: Clean dataset ready for SwissTarget analysis\n",
        "\n",
        "**Note**: SwissTarget prediction will be handled separately using local Python script"
      ],
      "metadata": {
        "id": "pipeline_header"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 1: Setup and Configuration"
      ],
      "metadata": {
        "id": "setup_header"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup_cell"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install pandas requests\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import urllib.request, urllib.error, urllib.parse, json, time, csv\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# --- Folder and Logging Configuration ---\n",
        "timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "main_folder_name = f\"curation_results_{timestamp}\"\n",
        "os.makedirs(main_folder_name, exist_ok=True)\n",
        "\n",
        "log_file_path = os.path.join(main_folder_name, \"curation_log.txt\")\n",
        "\n",
        "def write_log(message):\n",
        "    \"\"\"Function to write messages to log file and print to console.\"\"\"\n",
        "    log_message = f\"[{datetime.now().strftime('%H:%M:%S')}] {message}\"\n",
        "    print(log_message)\n",
        "    with open(log_file_path, \"a\", encoding='utf-8') as f:\n",
        "        f.write(log_message + \"\\n\")\n",
        "\n",
        "write_log(\"--- COMPOUND CURATION PIPELINE STARTED ---\")\n",
        "write_log(f\"Results folder: '{main_folder_name}'\")\n",
        "\n",
        "print(\"‚úÖ Setup completed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 2: Input Data Validation"
      ],
      "metadata": {
        "id": "validation_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read and validate input file\n",
        "input_filename = 'compound_data.csv'\n",
        "\n",
        "try:\n",
        "    df_input = pd.read_csv(input_filename, sep=',', encoding='utf-8')\n",
        "    write_log(f\"‚úÖ Successfully read input file: '{input_filename}'\")\n",
        "    write_log(f\"   - Total compounds: {len(df_input)}\")\n",
        "    write_log(f\"   - Columns: {list(df_input.columns)}\")\n",
        "    \n",
        "    # Validate required columns\n",
        "    if 'Name' not in df_input.columns:\n",
        "        raise ValueError(\"Required column 'Name' not found in input file\")\n",
        "    \n",
        "    # Preview data\n",
        "    print(\"\\n--- Input Data Preview ---\")\n",
        "    print(df_input.head())\n",
        "    \n",
        "    # Check for duplicates\n",
        "    duplicates = df_input['Name'].duplicated().sum()\n",
        "    if duplicates > 0:\n",
        "        write_log(f\"‚ö†Ô∏è Warning: Found {duplicates} duplicate compound names\")\n",
        "    \n",
        "except FileNotFoundError:\n",
        "    write_log(f\"‚ùå CRITICAL: File '{input_filename}' not found. Please upload the file.\")\n",
        "    df_input = pd.DataFrame()\n",
        "except Exception as e:\n",
        "    write_log(f\"‚ùå CRITICAL: Failed to read input file. Error: {e}\")\n",
        "    df_input = pd.DataFrame()"
      ],
      "metadata": {
        "id": "validation_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 3: PubChem API Functions"
      ],
      "metadata": {
        "id": "api_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cid_and_smiles(compound_name):\n",
        "    \"\"\"\n",
        "    Search for CID and SMILES using compound name variations.\n",
        "    Returns (cid, smiles, status).\n",
        "    \"\"\"\n",
        "    original_name = compound_name.strip()\n",
        "    \n",
        "    # Create name variations to improve search success\n",
        "    alpha_name = original_name.replace('Œ±', 'alpha').replace('Œ≤', 'beta').replace('Œ≥', 'gamma')\n",
        "    names_to_try = list(dict.fromkeys([original_name, alpha_name]))\n",
        "    \n",
        "    for i, name_attempt in enumerate(names_to_try):\n",
        "        write_log(f\"    > Searching: '{name_attempt}'\")\n",
        "        \n",
        "        try:\n",
        "            # Step 1: Get CID from compound name\n",
        "            name_encoded = urllib.parse.quote(name_attempt)\n",
        "            cid_url = f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/name/{name_encoded}/cids/JSON\"\n",
        "            \n",
        "            with urllib.request.urlopen(cid_url, timeout=20) as cid_request:\n",
        "                cid_reply = cid_request.read()\n",
        "                if not (cid_reply and len(cid_reply) > 0):\n",
        "                    continue\n",
        "                \n",
        "                cid_result = json.loads(cid_reply)['IdentifierList']['CID'][0]\n",
        "                write_log(f\"    > Found CID: {cid_result}\")\n",
        "                \n",
        "            # Step 2: Get SMILES from CID\n",
        "            smiles_url = f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/{cid_result}/property/SMILES/JSON\"\n",
        "            \n",
        "            with urllib.request.urlopen(smiles_url, timeout=20) as smiles_request:\n",
        "                smiles_reply = smiles_request.read()\n",
        "                if smiles_reply and len(smiles_reply) > 0:\n",
        "                    smiles_result = json.loads(smiles_reply)['PropertyTable']['Properties'][0]['SMILES']\n",
        "                    \n",
        "                    status_result = 'Success (Original Name)' if i == 0 else 'Success (Name Variant)'\n",
        "                    write_log(f\"    ‚úÖ SUCCESS: CID {cid_result}, SMILES obtained\")\n",
        "                    return cid_result, smiles_result, status_result\n",
        "                    \n",
        "        except Exception as e:\n",
        "            write_log(f\"    > Failed for '{name_attempt}': {str(e)[:50]}...\")\n",
        "            continue\n",
        "    \n",
        "    write_log(f\"    ‚ùå All attempts failed for '{original_name}'\")\n",
        "    return None, None, 'Failed'\n",
        "\n",
        "print(\"‚úÖ PubChem API functions defined successfully!\")"
      ],
      "metadata": {
        "id": "api_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 4: Data Processing and CID/SMILES Extraction"
      ],
      "metadata": {
        "id": "processing_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main processing logic\n",
        "if len(df_input) == 0:\n",
        "    write_log(\"‚ùå No input data available. Please check the input file.\")\n",
        "else:\n",
        "    # Prepare output filename\n",
        "    output_filename = os.path.join(main_folder_name, 'compounds_with_cid_smiles.csv')\n",
        "    \n",
        "    # Initialize counters\n",
        "    success_count = 0\n",
        "    failed_count = 0\n",
        "    failed_compounds = []\n",
        "    \n",
        "    write_log(f\"üöÄ Starting CID and SMILES extraction for {len(df_input)} compounds...\")\n",
        "    \n",
        "    # Process each compound\n",
        "    results = []\n",
        "    \n",
        "    for index, row in df_input.iterrows():\n",
        "        compound_name = str(row['Name']).strip()\n",
        "        write_log(f\"\\n[{index + 1}/{len(df_input)}] Processing: '{compound_name}'\")\n",
        "        \n",
        "        # Get CID and SMILES\n",
        "        cid, smiles, status = get_cid_and_smiles(compound_name)\n",
        "        \n",
        "        # Update counters\n",
        "        if 'Success' in status:\n",
        "            success_count += 1\n",
        "        else:\n",
        "            failed_count += 1\n",
        "            failed_compounds.append(compound_name)\n",
        "        \n",
        "        # Prepare result row\n",
        "        result_row = {\n",
        "            'Name': compound_name,\n",
        "            'PubChem_CID': cid,\n",
        "            'Smiles': smiles,\n",
        "            'Status': status\n",
        "        }\n",
        "        \n",
        "        # Add original columns if they exist\n",
        "        for col in df_input.columns:\n",
        "            if col != 'Name':\n",
        "                result_row[col] = row[col]\n",
        "        \n",
        "        results.append(result_row)\n",
        "        \n",
        "        # Be respectful to PubChem servers\n",
        "        time.sleep(0.5)\n",
        "    \n",
        "    # Create results DataFrame\n",
        "    df_results = pd.DataFrame(results)\n",
        "    \n",
        "    # Save results\n",
        "    df_results.to_csv(output_filename, index=False, encoding='utf-8')\n",
        "    \n",
        "    # Print summary\n",
        "    write_log(\"\\n\" + \"=\"*50)\n",
        "    write_log(\"‚ú® PROCESSING COMPLETED ‚ú®\")\n",
        "    write_log(f\"  - Total compounds processed: {len(df_input)}\")\n",
        "    write_log(f\"  - ‚úÖ Successful: {success_count}\")\n",
        "    write_log(f\"  - ‚ùå Failed: {failed_count}\")\n",
        "    write_log(f\"  - Success rate: {(success_count/len(df_input)*100):.1f}%\")\n",
        "    \n",
        "    if failed_compounds:\n",
        "        write_log(\"\\n--- Failed Compounds ---\")\n",
        "        for name in failed_compounds:\n",
        "            write_log(f\"  - {name}\")\n",
        "    \n",
        "    write_log(f\"\\nüíæ Results saved to: '{output_filename}'\")\n",
        "    write_log(\"=\"*50)\n",
        "    \n",
        "    # Preview results\n",
        "    print(\"\\n--- Results Preview ---\")\n",
        "    print(df_results.head())"
      ],
      "metadata": {
        "id": "processing_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 5: Data Quality Control and Cleaning"
      ],
      "metadata": {
        "id": "qc_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quality control and data cleaning\n",
        "if 'df_results' in locals() and len(df_results) > 0:\n",
        "    write_log(\"\\n--- QUALITY CONTROL PHASE ---\")\n",
        "    \n",
        "    # Filter successful compounds\n",
        "    success_mask = df_results['Status'].str.contains('Success', na=False)\n",
        "    df_clean = df_results[success_mask].copy()\n",
        "    \n",
        "    # Additional validation\n",
        "    initial_count = len(df_clean)\n",
        "    \n",
        "    # Remove rows with missing SMILES\n",
        "    df_clean = df_clean.dropna(subset=['Smiles'])\n",
        "    \n",
        "    # Remove rows with empty SMILES\n",
        "    df_clean = df_clean[df_clean['Smiles'].str.strip() != '']\n",
        "    \n",
        "    final_count = len(df_clean)\n",
        "    removed_count = initial_count - final_count\n",
        "    \n",
        "    write_log(f\"Quality control results:\")\n",
        "    write_log(f\"  - Initial successful compounds: {initial_count}\")\n",
        "    write_log(f\"  - Removed due to invalid SMILES: {removed_count}\")\n",
        "    write_log(f\"  - Final clean compounds: {final_count}\")\n",
        "    \n",
        "    # Save clean dataset\n",
        "    clean_filename = os.path.join(main_folder_name, 'data_compounds_final_full.csv')\n",
        "    df_clean.to_csv(clean_filename, index=False, encoding='utf-8')\n",
        "    \n",
        "    write_log(f\"\\n‚úÖ Clean dataset saved to: '{clean_filename}'\")\n",
        "    write_log(\"   This file is ready for SwissTarget analysis!\")\n",
        "    \n",
        "    # Final statistics\n",
        "    write_log(\"\\n--- FINAL STATISTICS ---\")\n",
        "    write_log(f\"  - Original compounds: {len(df_input)}\")\n",
        "    write_log(f\"  - Successfully processed: {success_count}\")\n",
        "    write_log(f\"  - Ready for SwissTarget: {final_count}\")\n",
        "    write_log(f\"  - Overall success rate: {(final_count/len(df_input)*100):.1f}%\")\n",
        "    \n",
        "    # Preview clean data\n",
        "    print(\"\\n--- Clean Dataset Preview ---\")\n",
        "    print(df_clean[['Name', 'PubChem_CID', 'Smiles', 'Status']].head(10))\n",
        "    \n",
        "    print(f\"\\nüéØ Next Step: Use the file '{clean_filename}' with your SwissTarget Python script!\")\n",
        "    \n",
        "else:\n",
        "    write_log(\"‚ùå No results available for quality control. Please run the processing step first.\")"
      ],
      "metadata": {
        "id": "qc_cell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cell 6: Download Results (Optional)"
      ],
      "metadata": {
        "id": "download_header"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Download results in Google Colab\n",
        "try:\n",
        "    from google.colab import files\n",
        "    \n",
        "    # Check if files exist\n",
        "    if 'clean_filename' in locals():\n",
        "        print(\"Downloading clean dataset...\")\n",
        "        files.download(clean_filename)\n",
        "        \n",
        "        print(\"Downloading processing log...\")\n",
        "        files.download(log_file_path)\n",
        "        \n",
        "        print(\"‚úÖ Files downloaded successfully!\")\n",
        "    else:\n",
        "        print(\"‚ùå No clean dataset available for download.\")\n",
        "        \n",
        "except ImportError:\n",
        "    print(\"‚ÑπÔ∏è Not running in Google Colab. Files are saved locally.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Download failed: {e}\")\n",
        "\n",
        "print(\"\\nüéâ Compound curation pipeline completed!\")\n",
        "print(\"   You can now use the cleaned dataset with your SwissTarget analysis script.\")"
      ],
      "metadata": {
        "id": "download_cell"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}